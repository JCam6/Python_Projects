{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "96816ed7-b08a-4ca3-abb9-f99880c3535d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## ML For Fraud Detection\n",
    "#### Author\n",
    "##### Jermaine Cameron\n",
    "#### Date\n",
    "##### July 2021\n",
    "#### Dataset\n",
    "##### Synthetic Financial Dataset For Fraud Detection (source: www.kaggle.com)\n",
    "#### References\n",
    "##### Financial Fraud Detection using Decision Tree Machine Learning Models (Elena Boiarskaia, www.databricks.com, 2019)\n",
    "##### Fraud Detection on Financial Transactions with Machine Learning on Google Cloud (Google, www.qwiklabs.com)\n",
    "##### Data Mining: Practical Machine Learning Tools and Techniques (Ian Witten, Morgan Kaufmann Publishing, 2011)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "96bd98e3-9cb4-4367-9f49-1a30ae072a93",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Step 1: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\jc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.2.0)\n",
      "Requirement already satisfied: py4j==0.10.9.2 in c:\\users\\jc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyspark) (0.10.9.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in c:\\users\\jc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.5.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\jc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\jc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\jc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (9.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\jc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.28.5)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\jc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.22.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\jc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.0.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: sklearn in c:\\users\\jc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\jc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sklearn) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\jc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sklearn) (1.22.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\jc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\jc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sklearn) (1.7.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\jc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sklearn) (3.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyspark\n",
    "%pip install matplotlib\n",
    "%pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2326db03-4486-4edd-bd22-5fc9fddec233",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "\n",
    "import pyspark\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import itertools\n",
    "from sklearn import metrics, datasets, neighbors\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import avg\n",
    "from pyspark.sql.functions import lit, expr, col, column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6482be4c-f067-47c9-b0ac-35c938b94601",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pyspark' has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15732/2605288137.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdelimiter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\",\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m   \u001b[1;33m.\u001b[0m\u001b[0moption\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"inferSchema\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfer_schema\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m   \u001b[1;33m.\u001b[0m\u001b[0moption\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"header\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'true'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pyspark' has no attribute 'read'"
     ]
    }
   ],
   "source": [
    "# Import synthetic fraud ATM csv data file\n",
    "\n",
    "file_location = \"PS_20174392719_1491204439457_log.csv\"\n",
    "file_type = \"csv\"\n",
    "\n",
    "infer_schema = \"false\"\n",
    "delimiter = \",\"\n",
    "\n",
    "df = (\n",
    "    spark.read.format(file_type)\n",
    "    .option(\"inferSchema\", infer_schema)\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"sep\", delimiter)\n",
    "    .load(file_location)\n",
    ")\n",
    "\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "be62b669-85a0-4dc9-b0e9-a125f1b2f962",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Change data field types for analysis\n",
    "\n",
    "df = (\n",
    "    df.withColumn(\"amount\", F.col(\"amount\").cast(\"double\"))\n",
    "    .withColumn(\"oldbalanceOrg\", F.col(\"oldbalanceOrg\").cast(\"double\"))\n",
    "    .withColumn(\"newbalanceOrig\", F.col(\"newbalanceOrig\").cast(\"double\"))\n",
    "    .withColumn(\"oldbalanceDest\", F.col(\"oldbalanceDest\").cast(\"double\"))\n",
    "    .withColumn(\"newbalanceDest\", F.col(\"newbalanceDest\").cast(\"double\"))\n",
    ")\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8a60ae60-f22f-4b96-99a4-b5c8a12f990b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Add columns calculating change in account balances after transactions\n",
    "\n",
    "df = df.withColumn(\"orgDiff\", df.newbalanceOrig - df.oldbalanceOrg).withColumn(\n",
    "    \"destDiff\", df.newbalanceDest - df.oldbalanceDest\n",
    ")\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5d7b385e-471f-496a-ba28-0c66d8c01ca3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# View cases initially flagged as fraud in the original data file\n",
    "\n",
    "initially_flagged_fraud = df.filter(df.isFlaggedFraud == 1).count()\n",
    "print(initially_flagged_fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5bded17e-7d6f-40c1-8b9e-9c5621621ac7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# View cases that are fraud in original data file\n",
    "\n",
    "initially_isfraud = df.filter(df.isFraud == 1).count()\n",
    "print(initially_isfraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8816204f-a857-4117-9a87-a638a43f5974",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# View the total number of cases in the dataset\n",
    "\n",
    "total_cases_df = df.count()\n",
    "print(\"The total number of cases in the data set are: \" + str(total_cases_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "03f4aee9-40cb-4e91-baad-0b9252507315",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Step 2: Create Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e2fe9373-ea8c-4ac4-89c2-2ab59a58b674",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# The dataset contains rare events of fraud which is expected.\n",
    "# Add new fraud classification label based on data that follows the pattern defined here in order to make the sequence of fraudulent behaviour more obvious for the model\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"label\",\n",
    "    F.when(\n",
    "        (\n",
    "            (df.oldbalanceOrg <= 50000)\n",
    "            & (df.type == \"TRANSFER\")\n",
    "            & (df.newbalanceDest <= 100)\n",
    "        )\n",
    "        | ((df.oldbalanceOrg > 50000) & (df.newbalanceOrig <= 10))\n",
    "        | (\n",
    "            (df.oldbalanceOrg > 50000)\n",
    "            & (df.newbalanceOrig > 10)\n",
    "            & (df.amount > 1000000)\n",
    "        ),\n",
    "        1,\n",
    "    ).otherwise(0),\n",
    ")\n",
    "\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "dbf1f365-827b-470b-b835-27271d639f08",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# View cases that are manually categorized as fraud based on a rule pattern\n",
    "\n",
    "fraud_cases = df.filter(df.label == 1).count()\n",
    "total_cases = df.count()\n",
    "fraud_pct = 1.0 * fraud_cases / total_cases\n",
    "\n",
    "print(\"The total number of cases are: \" + str(total_cases))\n",
    "print(\"The number of fraud cases identified by the pattern are: \" + str(fraud_cases))\n",
    "print(\"The percentage of cases identified as fraud are: \" + str(fraud_pct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9c6e202e-ec01-49d1-b80c-a3f7d0d88b45",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create view for charts\n",
    "\n",
    "df.createOrReplaceTempView(\"tmpviewchart\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b70ab5ad-e571-43c5-b3e1-dec88f4b970d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Step 3: Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "31b2fd98-2922-4d0f-b452-ef6ecd15448a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create training and test datasets based on an 80/20 hold out approach\n",
    "\n",
    "(train, test) = df.randomSplit([0.8, 0.2], seed=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "dbaefd33-0e4e-482a-af82-87ca17e59701",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cache and print counts for training and test data sets\n",
    "\n",
    "train.cache()\n",
    "test.cache()\n",
    "\n",
    "print(\"The total count is: %s\" % (df.count()))\n",
    "print(\"The training count is: %s\" % (train.count()))\n",
    "print(\"The test count is: %s\" % (test.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8ccd20c1-e47e-48df-bf4d-fcf9e1e49bd5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Step 4: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e941a270-5705-424f-834a-55a10a6af07e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Configure a decision tree model based on the binary classification desired from the dataset\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"type\", outputCol=\"typeIndexed\")\n",
    "va = VectorAssembler(\n",
    "    inputCols=[\n",
    "        \"typeIndexed\",\n",
    "        \"amount\",\n",
    "        \"oldbalanceOrg\",\n",
    "        \"newbalanceOrig\",\n",
    "        \"oldbalanceDest\",\n",
    "        \"newbalanceDest\",\n",
    "        \"orgDiff\",\n",
    "        \"destDiff\",\n",
    "    ],\n",
    "    outputCol=\"features\",\n",
    ")\n",
    "dt = DecisionTreeClassifier(\n",
    "    labelCol=\"label\", featuresCol=\"features\", seed=54321, maxDepth=5\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(stages=[indexer, va, dt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "94f27c8d-46d8-468a-9d50-ed03b2de8534",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define model variable based on ML pipeline above\n",
    "\n",
    "dt_model = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "10cdebc9-487a-4c03-aaa4-9fbec44fb6a1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Transform model variable to create training and test predictions\n",
    "\n",
    "train_pred = dt_model.transform(train)\n",
    "test_pred = dt_model.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "128618a4-9a1c-41f2-b3ef-d64ffa232f94",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Step 5: Evaluate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e9cbcd4e-33d7-4166-a621-9ed126487eac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define model evaluation metric\n",
    "\n",
    "evaluatorPR = BinaryClassificationEvaluator(\n",
    "    labelCol=\"label\", rawPredictionCol=\"prediction\", metricName=\"areaUnderPR\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d6d75acc-907b-4b8e-8c9b-ccc52ccf1f51",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on training dataset\n",
    "\n",
    "pr_train = evaluatorPR.evaluate(train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ba476adb-f440-48b4-a7d4-0dce56664450",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on test dataset\n",
    "\n",
    "pr_test = evaluatorPR.evaluate(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8d0f0ba4-f246-4b35-8323-f92512b01b1d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Print out the Precision-Recall curve values\n",
    "\n",
    "print(\"PR train:\", pr_train)\n",
    "print(\"PR test:\", pr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2528f8f1-8613-4369-9fa6-edc2307cd8ea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check confustion matrix false negative, false positive, ture negative, and true positive values\n",
    "\n",
    "fn = test_pred.filter((test_pred.label == 1) & (test_pred.prediction == 0)).count()\n",
    "fp = test_pred.filter((test_pred.label == 0) & (test_pred.prediction == 1)).count()\n",
    "tn = test_pred.filter((test_pred.label == 0) & (test_pred.prediction == 0)).count()\n",
    "tp = test_pred.filter((test_pred.label == 1) & (test_pred.prediction == 1)).count()\n",
    "\n",
    "cm_dt = test_pred.groupBy(\"label\", \"prediction\").count()\n",
    "display(cm_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e7926974-5e47-4cb1-954e-c97752675f61",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Print confusion matrix values to check above dataframe\n",
    "\n",
    "print(fn)\n",
    "print(fp)\n",
    "print(tn)\n",
    "print(tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "79178b5e-df0f-4adb-bd53-9dbd45bab9a8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Step 6: Balance Trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "54b95baa-e9c9-4c40-a137-beb6b2fe55fe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a balanced training set by under sampling the non fraud cases so that the trainset has equal number of non fraud and fraud classifications to train and tune a better model\n",
    "\n",
    "dfNo = train.filter(train.label == 0)\n",
    "dfFraud = train.filter(train.label == 1)\n",
    "TotalTrain = train.count()\n",
    "TotalFraud = dfFraud.count()\n",
    "percent_Fraud = TotalFraud / TotalTrain\n",
    "df_balance = dfNo.sample(False, percent_Fraud, seed=92285).union(dfFraud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "695d7dfa-a786-4dd3-802c-1a431b313b39",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Step 7: Tune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "06ccccc1-ca3a-46d9-b90e-0b4469cb670f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Tune model with cross validation on the balanced training data\n",
    "\n",
    "evaluatorROC = BinaryClassificationEvaluator(\n",
    "    labelCol=\"label\", rawPredictionCol=\"prediction\", metricName=\"areaUnderROC\"\n",
    ")\n",
    "\n",
    "paramGrid = (\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(dt.maxDepth, [5, 10, 15])\n",
    "    .addGrid(dt.maxBins, [10, 20, 30])\n",
    "    .build()\n",
    ")\n",
    "\n",
    "crossval_balance = CrossValidator(\n",
    "    estimator=dt, estimatorParamMaps=paramGrid, evaluator=evaluatorROC, numFolds=3\n",
    ")\n",
    "pipelineCV_balance = Pipeline(stages=[indexer, va, crossval_balance])\n",
    "cvModel_balance = pipelineCV_balance.fit(df_balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0779f0f1-18bf-4a09-868c-6279e8aac909",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Transform tuned model variable to create training and test predictions\n",
    "\n",
    "train_pred_balance = cvModel_balance.transform(df_balance)\n",
    "test_pred_balance = cvModel_balance.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "199a2740-a222-459a-a062-e6356d48375f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check cross validation tuned confustion matrix false negative, false positive, ture negative, and true positive values\n",
    "\n",
    "fn_balance = test_pred_balance.filter(\n",
    "    (test_pred_balance.label == 1) & (test_pred_balance.prediction == 0)\n",
    ").count()\n",
    "fp_balance = test_pred_balance.filter(\n",
    "    (test_pred_balance.label == 0) & (test_pred_balance.prediction == 1)\n",
    ").count()\n",
    "tn_balance = test_pred_balance.filter(\n",
    "    (test_pred_balance.label == 0) & (test_pred_balance.prediction == 0)\n",
    ").count()\n",
    "tp_balance = test_pred_balance.filter(\n",
    "    (test_pred_balance.label == 1) & (test_pred_balance.prediction == 1)\n",
    ").count()\n",
    "\n",
    "cm_dt_balance = test_pred_balance.groupBy(\"label\", \"prediction\").count()\n",
    "display(cm_dt_balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "25797dcc-7b1a-4ff1-888d-0cc549628484",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Print confusion matrix values to check above dataframe\n",
    "\n",
    "print(fn_balance)\n",
    "print(fp_balance)\n",
    "print(tn_balance)\n",
    "print(tp_balance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "cb4d3c79-9911-49dc-96c5-0accdbcdaaec",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Step 8: Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "068e78ff-18d7-4870-a6e7-dc4b3acaa34f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Run experiment with gradient boosted tree model (58229)\n",
    "\n",
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\", seed=58228)\n",
    "gbt_pipeline = Pipeline(stages=[indexer, va, gbt])\n",
    "gbt_model = gbt_pipeline.fit(df_balance)\n",
    "\n",
    "train_pred_gbt_balance = gbt_model.transform(df_balance)\n",
    "test_pred_gbt_balance = gbt_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "16de09c2-0ea0-4c8e-8e0d-7fa8e9bddd1a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check gbt confustion matrix false negative, false positive, ture negative, and true positive values\n",
    "\n",
    "fn_gbt = test_pred_gbt_balance.filter(\n",
    "    (test_pred_gbt_balance.label == 1) & (test_pred_gbt_balance.prediction == 0)\n",
    ").count()\n",
    "fp_gbt = test_pred_gbt_balance.filter(\n",
    "    (test_pred_gbt_balance.label == 0) & (test_pred_gbt_balance.prediction == 1)\n",
    ").count()\n",
    "tn_gbt = test_pred_gbt_balance.filter(\n",
    "    (test_pred_gbt_balance.label == 0) & (test_pred_gbt_balance.prediction == 0)\n",
    ").count()\n",
    "tp_gbt = test_pred_gbt_balance.filter(\n",
    "    (test_pred_gbt_balance.label == 1) & (test_pred_gbt_balance.prediction == 1)\n",
    ").count()\n",
    "\n",
    "cm_gbt = test_pred_gbt_balance.groupBy(\"label\", \"prediction\").count()\n",
    "display(cm_gbt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2780033f-1337-482f-9b2b-e48da9b25c98",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Print confusion matrix values to check above dataframe\n",
    "\n",
    "print(fn_gbt)\n",
    "print(fp_gbt)\n",
    "print(tn_gbt)\n",
    "print(tp_gbt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e9e3aa50-6537-4b39-bc26-68282ce3527a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# Create an initial RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "rf_pipeline = Pipeline(stages=[indexer, va, rf])\n",
    "rf_model = rf_pipeline.fit(df_balance)\n",
    "\n",
    "train_pred_rf_balance = rf_model.transform(df_balance)\n",
    "test_pred_rf_balance = rf_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "cf34559f-a617-4d76-a505-75bb3be866a7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fn_rf = test_pred_rf_balance.filter(\n",
    "    (test_pred_rf_balance.label == 1) & (test_pred_rf_balance.prediction == 0)\n",
    ").count()\n",
    "fp_rf = test_pred_rf_balance.filter(\n",
    "    (test_pred_rf_balance.label == 0) & (test_pred_rf_balance.prediction == 1)\n",
    ").count()\n",
    "tn_rf = test_pred_rf_balance.filter(\n",
    "    (test_pred_rf_balance.label == 0) & (test_pred_rf_balance.prediction == 0)\n",
    ").count()\n",
    "tp_rf = test_pred_rf_balance.filter(\n",
    "    (test_pred_rf_balance.label == 1) & (test_pred_rf_balance.prediction == 1)\n",
    ").count()\n",
    "\n",
    "cm_rf = test_pred_rf_balance.groupBy(\"label\", \"prediction\").count()\n",
    "display(cm_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "bf2677b2-52c8-42f2-8d82-1402bec034a9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Step 9: Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "df8cb5d7-1e65-4962-abd4-2dc72fcb3228",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create variable needed for 1st confusion matrix graphic\n",
    "\n",
    "cmt = spark.createDataFrame([(1, 0), (0, 0), (1, 1), (0, 1)], [\"label\", \"prediction\"])\n",
    "cmt.createOrReplaceTempView(\"cmt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "dc8e58aa-88b8-4de2-948a-97fafe22c4b3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create plot function for confusion matrix graphic\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, title):\n",
    "    plt.gcf().clear()\n",
    "    fig = plt.figure(1)\n",
    "    classes = [\"Fraud\", \"No Fraud\"]\n",
    "    plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Reds)\n",
    "    plt.title(title)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    normalize = False\n",
    "    fmt = \"d\"\n",
    "    thresh = cm.max() / 2.0\n",
    "\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(\n",
    "            j,\n",
    "            i,\n",
    "            format(cm[i, j], fmt),\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "        )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "\n",
    "    image = fig\n",
    "    fig.savefig(\"confusion-matrix.png\")\n",
    "    display(image)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9163516d-74c9-4488-a73f-96b0a4d81ed6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create view for 1st confusion matrix graphic\n",
    "\n",
    "test_pred.createOrReplaceTempView(\"test_pred\")\n",
    "test_pred_cmdf = spark.sql(\n",
    "    \"select a.label, a.prediction, coalesce(b.count, 0) as count from cmt a left outer join (select label, prediction, count(1) as count from test_pred group by label, prediction) b on b.label = a.label and b.prediction = a.prediction order by a.label desc, a.prediction desc\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "caa184b1-11d0-4dbe-932c-dc2e759b8643",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create pandas dataframe for 1st confusion matrix graphic\n",
    "\n",
    "cm_pdf = test_pred_cmdf.toPandas()\n",
    "cm_1d = np.array(cm_pdf[\"count\"])\n",
    "cm = np.reshape(cm_1d, (-1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "475ff523-4e74-4007-8345-237198dea4c7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm, \"Confusion Matrix (DT)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c896c15a-ffc9-41e1-8e4c-73680f499fab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create variable needed for confusion matrix of tuned model\n",
    "\n",
    "cmt_tuned = spark.createDataFrame(\n",
    "    [(1, 0), (0, 0), (1, 1), (0, 1)], [\"label\", \"prediction\"]\n",
    ")\n",
    "cmt_tuned.createOrReplaceTempView(\"cmt_tuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6720efdb-c597-4d93-a193-5257ecec9465",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create view for tuned confusion matrix graphic\n",
    "\n",
    "test_pred_balance.createOrReplaceTempView(\"test_pred_balance\")\n",
    "test_pred_balance_cmdf = spark.sql(\n",
    "    \"select a.label, a.prediction, coalesce(b.count, 0) as count from cmt_tuned a left outer join (select label, prediction, count(1) as count from test_pred_balance group by label, prediction) b on b.label = a.label and b.prediction = a.prediction order by a.label desc, a.prediction desc\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7c41feea-327c-466b-9185-38754f8bbfda",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create pandas dataframe for tuned confusion matrix graphic\n",
    "\n",
    "cm_tuned_pdf = test_pred_balance_cmdf.toPandas()\n",
    "cm_tuned_1d = np.array(cm_tuned_pdf[\"count\"])\n",
    "cm_tuned = np.reshape(cm_tuned_1d, (-1, 2))\n",
    "\n",
    "plot_confusion_matrix(cm_tuned, \"Confusion Matrix (Tuned DT)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "17fe759c-f07c-476d-8d7f-e59feba8b255",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create variable needed for confusion matrix of final model\n",
    "\n",
    "cmt_tuned_final = spark.createDataFrame(\n",
    "    [(1, 0), (0, 0), (1, 1), (0, 1)], [\"label\", \"prediction\"]\n",
    ")\n",
    "cmt_tuned_final.createOrReplaceTempView(\"cmt_tuned_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8f8f2c93-951e-4e35-a26d-471544a492ed",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test_pred_gbt_balance.createOrReplaceTempView(\"test_pred_gbt_balance\")\n",
    "test_pred_gbt_balance_cmdf = spark.sql(\n",
    "    \"select a.label, a.prediction, coalesce(b.count, 0) as count from cmt_tuned_final a left outer join (select label, prediction, count(1) as count from test_pred_gbt_balance group by label, prediction) b on b.label = a.label and b.prediction = a.prediction order by a.label desc, a.prediction desc\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f4b1fb49-318f-4b1a-a409-f08ff4e91790",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cm_tuned_final_pdf = test_pred_gbt_balance_cmdf.toPandas()\n",
    "cm_tuned_final_1d = np.array(cm_tuned_final_pdf[\"count\"])\n",
    "cm_tuned_final = np.reshape(cm_tuned_final_1d, (-1, 2))\n",
    "\n",
    "plot_confusion_matrix(cm_tuned_final, \"Confusion Matrix (GBT)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9356ada1-f7e5-4629-a0c3-56f64c213350",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Step 10: Add Visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "04e98013-a76d-4271-9504-4c4045573c0a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Add graphics for a dashboard view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ad6b543f-ebcd-403b-91cd-11bdfe7ab410",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select label, count(1) as `Transactions`, sum(amount) from tmpviewchart group by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f84521e0-83c3-4df3-8078-760f3d69c15b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select type, sum(amount), count(1) from tmpviewchart group by type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "812235c7-eb7a-4d53-bc6d-c3c37a5730ef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(dt_model.stages[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "73a34975-537f-4936-8101-443b09c548d8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [
    {
     "elements": [
      {
       "elementNUID": "475ff523-4e74-4007-8345-237198dea4c7",
       "elementType": "command",
       "guid": "452858f9-0e9f-4cf9-a1a7-f26014a39a26",
       "options": null,
       "position": {
        "height": 8,
        "width": 8,
        "x": 0,
        "y": 6,
        "z": null
       },
       "resultIndex": null
      },
      {
       "elementNUID": "f4b1fb49-318f-4b1a-a409-f08ff4e91790",
       "elementType": "command",
       "guid": "b0c9b1f7-483f-477f-aa8f-01eeeaa361f9",
       "options": null,
       "position": {
        "height": 8,
        "width": 8,
        "x": 16,
        "y": 6,
        "z": null
       },
       "resultIndex": null
      },
      {
       "elementNUID": "7c41feea-327c-466b-9185-38754f8bbfda",
       "elementType": "command",
       "guid": "b7388933-30bf-4a20-9197-992524f6701a",
       "options": {
        "autoScaleImg": false,
        "scale": 0,
        "showTitle": false,
        "titleAlign": "center"
       },
       "position": {
        "height": 8,
        "width": 8,
        "x": 8,
        "y": 6,
        "z": null
       },
       "resultIndex": null
      }
     ],
     "globalVars": {},
     "guid": "be09a23d-9af2-427d-b022-a3df03f82134",
     "layoutOption": {
      "grid": true,
      "stack": false
     },
     "nuid": "5ebbf648-18f7-4e56-8e0f-c907af5d77de",
     "origId": 1259726018232015,
     "title": "Fraud Detection",
     "version": "DashboardViewV1",
     "width": 1024
    }
   ],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "ML_Fraud_Detection",
   "notebookOrigID": 1259726018231973,
   "widgets": {}
  },
  "interpreter": {
   "hash": "ff1165b375dc5bb4b21feca85b3633f09547fde6a7762e0b5b7e533d09e0d81f"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
